import os
import pickle
import itertools
from metrics.compute_score import *


SCORE_DICT = {
    "avg_1_spbleu": compute_avg_1_spbleu,
    "avg_10_spbleu": compute_avg_10_spbleu,
    "avg_50_spbleu": compute_avg_50_spbleu,
    "avg_100_spbleu": compute_avg_50_spbleu,
    "bleu": compute_bleu,
    "spbleu": compute_spbleu,
    "chrf": compute_chrf,
    "bertscore": compute_bertscore,
    }


def postprocess_text(preds, labels):
    decoded_preds = [pred[0].strip() for pred in preds]
    decoded_labels = [label.strip() for label in labels]
    if isinstance(decoded_preds, tuple):
        decoded_preds = decoded_preds[0]
    return decoded_preds, decoded_labels


def get_path_name(src_lang, tgt_lang,
                  dataset_name, model_name, metrics,
                  _test=False, _unpaired=False,
                  _self=False, _corpus_level=False, _sys=None):
    train_test_prefix = "test_" if _test else "train_"
    unpaired_prefix = "unpaired_" if _unpaired else ""
    direction_prefix = "self_" if _self else "trans_from_"
    sample_corpus_prefix = "corpus_" if _corpus_level else "sample_"

    if _sys:
        dir_path = f"local_{dataset_name}/{src_lang}_{tgt_lang}/{_sys}/{model_name}"

    else:
        dir_path = f"local_{dataset_name}/{src_lang}_{tgt_lang}/{model_name}"
    subdir_translation_paths = {"src": f"{train_test_prefix}{unpaired_prefix}{direction_prefix}src.pkl",
                                "tgt": f"{train_test_prefix}{unpaired_prefix}{direction_prefix}tgt.pkl"}
    subdir_score_paths = {
        f"{k1}-{k2}": f"{train_test_prefix}{unpaired_prefix}{direction_prefix}{k1}_{sample_corpus_prefix}{k2}.pkl"
        for k1, k2 in itertools.product(["src", "tgt"], metrics)}

    try:
        os.makedirs(dir_path)
    except:
        pass

    return dir_path, subdir_translation_paths, subdir_score_paths


class Scores(object):
    def __init__(self,
                 src_ref, src_pred,
                 tgt_ref, tgt_pred,
                 src_lang, tgt_lang,
                 dataset_name, model_name, metrics,
                 sys=None,
                 _test=False, _unpaired=False,
                 _self=False, _corpus_level=False
                 ):
        _KWARGS_DESCRIPTION = """
        Args:
            Data:
                src_ref: Reference in the source language.
                src_pred: Prediction in the source language.
                
                tgt_ref: Reference in the target language.
                tgt_pred: Prediction in the target language.
                
                src_lang: The source langauge
                tgt_lang: The target language
            
            Path Name:    
                dataset_name: Dataset name, e.g. "flores-101"
                model_name: Model name, e.g. "mbart-50"
                metrics: Metric name, e.g. ["spbleu"]
            
            Attributes:    
                test: Check if the data is from test split. False as default.
                unpaired: Check if the data is from unpaired samples. False as default.
                self: Check if the data is generated by back-translation. False as default.
                corpus_level: Check if the scores need to be computed in corpus level. False as default.
        """
        self.data = dict()
        self.data['src'] = src_pred, src_ref
        self.data['tgt'] = tgt_pred, tgt_ref
        self.src_lang, self.tgt_lang = src_lang, tgt_lang
        self.dir_path, self.subdir_translation_paths, \
        self.subdir_score_paths = get_path_name(src_lang, tgt_lang,
                                                dataset_name, model_name, metrics,
                                                _test=_test, _unpaired=_unpaired,
                                                _self=_self, _corpus_level=_corpus_level, _sys=sys)
        self.metrics = metrics
        self.corpus_level = _corpus_level

    def store_translation_results(self, directions=["src", "tgt"]):
        for k in directions:
            with open(f"{self.dir_path}/{self.subdir_translation_paths[k]}", "wb") as f:
                pickle.dump(self.data[k][0], f)

    def store_score_results(self, directions=["src", "tgt"]):
        for k1, k2 in itertools.product(directions, self.metrics):
            try:
                with open(f"{self.dir_path}/{self.subdir_score_paths[f'{k1}-{k2}']}", "rb") as f:
                    assert pickle.load(f)
            except:
                with open(f"{self.dir_path}/{self.subdir_score_paths[f'{k1}-{k2}']}", "wb") as f:
                    if k1 == "src":
                        pickle.dump(SCORE_DICT[k2](*self.data[k1], self.src_lang, self.corpus_level), f)
                    else:
                        pickle.dump(SCORE_DICT[k2](*self.data[k1], self.tgt_lang, self.corpus_level), f)
