{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sacrebleu\n",
    "import pickle\n",
    "import glob\n",
    "import itertools\n",
    "import numpy as np\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bleu(spbleu_data):\n",
    "    spbleu_dict = dict()\n",
    "    for i,k in enumerate([\"bleu_max1\", \"bleu_max2\", \"bleu_max3\", \"bleu_max4\"]):\n",
    "        for attr in [\"score\",\"counts\", \"totals\"]:\n",
    "            if attr in [\"score\", \"counts\", \"totals\"]:\n",
    "                spbleu_dict[f\"{k}-score\"] = getattr(spbleu_data[k],\"precisions\")[i]\n",
    "                spbleu_dict[f\"{k}-totals\"] = getattr(spbleu_data[k],\"totals\")[i]\n",
    "                spbleu_dict[f\"{k}-counts\"] = getattr(spbleu_data[k],\"counts\")[i]\n",
    "            else:\n",
    "                spbleu_dict[f\"{k}-{attr}\"] = getattr(spbleu_data[k],attr)\n",
    "            if i == 3:\n",
    "                try:\n",
    "                    spbleu_dict[f\"bleu-ratio\"] = getattr(spbleu_data[\"bleu_max4\"],\"ratio\")\n",
    "                except:\n",
    "                    if spbleu_data[\"bleu_max4\"].ref_len:\n",
    "                        spbleu_dict[f\"bleu-ratio\"] = spbleu_data[\"bleu_max4\"].sys_len / spbleu_data[\"bleu_max4\"].ref_len\n",
    "                    else:\n",
    "                        spbleu_dict[f\"bleu-ratio\"] = 0\n",
    "                spbleu_dict[f\"bleu_final-score\"] = getattr(spbleu_data[\"bleu_max4\"],\"score\")\n",
    "                spbleu_dict[f\"bleu-bp\"] = getattr(spbleu_data[\"bleu_max4\"],\"bp\")\n",
    "                spbleu_dict[f\"bleu-ref_len\"] = getattr(spbleu_data[\"bleu_max4\"],\"ref_len\")\n",
    "                spbleu_dict[f\"bleu-sys_len\"] = getattr(spbleu_data[\"bleu_max4\"],\"sys_len\")\n",
    "    return spbleu_dict\n",
    "\n",
    "def convert_spbleu(spbleu_data):\n",
    "    spbleu_dict = dict()\n",
    "    for i,k in enumerate([\"spbleu_max1\", \"spbleu_max2\", \"spbleu_max3\", \"spbleu_max4\"]):\n",
    "        for attr in [\"score\",\"counts\", \"totals\"]:\n",
    "            if attr in [\"score\", \"counts\", \"totals\"]:\n",
    "                spbleu_dict[f\"{k}-score\"] = getattr(spbleu_data[k],\"precisions\")[i]\n",
    "                spbleu_dict[f\"{k}-totals\"] = getattr(spbleu_data[k],\"totals\")[i]\n",
    "                spbleu_dict[f\"{k}-counts\"] = getattr(spbleu_data[k],\"counts\")[i]\n",
    "            else:\n",
    "                spbleu_dict[f\"{k}-{attr}\"] = getattr(spbleu_data[k],attr)\n",
    "            if i == 3:\n",
    "                try:\n",
    "                    spbleu_dict[f\"spbleu-ratio\"] = getattr(spbleu_data[\"spbleu_max4\"],\"ratio\")\n",
    "                except:\n",
    "                    if spbleu_data[\"spbleu_max4\"].ref_len:\n",
    "                        spbleu_dict[f\"spbleu-ratio\"] = spbleu_data[\"spbleu_max4\"].sys_len / spbleu_data[\"spbleu_max4\"].ref_len\n",
    "                    else:\n",
    "                        spbleu_dict[f\"spbleu-ratio\"] = 0\n",
    "                spbleu_dict[f\"spbleu_final-score\"] = getattr(spbleu_data[\"spbleu_max4\"],\"score\")\n",
    "                spbleu_dict[f\"spbleu-bp\"] = getattr(spbleu_data[\"spbleu_max4\"],\"bp\")\n",
    "                spbleu_dict[f\"spbleu-ref_len\"] = getattr(spbleu_data[\"spbleu_max4\"],\"ref_len\")\n",
    "                spbleu_dict[f\"spbleu-sys_len\"] = getattr(spbleu_data[\"spbleu_max4\"],\"sys_len\")\n",
    "    return spbleu_dict\n",
    "\n",
    "def convert_chrf(chrf_data):\n",
    "    chrf_dict = dict()\n",
    "    for k in [\"spbleu_max1\", \"spbleu_max2\", \"spbleu_max3\", \"spbleu_max4\", \"spbleu_max5\", \"spbleu_max6\"]:\n",
    "        for attr in [\"score\"]:\n",
    "            tmp_k = k.replace(\"spbleu\",\"chrf\")\n",
    "            chrf_dict[f\"{tmp_k}-{attr}\"] = getattr(chrf_data[k],attr)\n",
    "    return chrf_dict\n",
    "\n",
    "def convert_ter(ter_data):\n",
    "    ter_dict = dict()\n",
    "    ter_dict[f\"ter-score\"] = getattr(ter_data[\"ter\"],\"score\")\n",
    "    return ter_dict\n",
    "\n",
    "def convert_bertscore(bertscore_data):\n",
    "    bertscore_dict = dict()\n",
    "    for attr in [\"score\"]:\n",
    "        bertscore_dict[f\"bertscore-p\"] = bertscore_data[\"bertscore\"][0].mean().item()*100\n",
    "        bertscore_dict[f\"bertscore-r\"] = bertscore_data[\"bertscore\"][1].mean().item()*100\n",
    "        bertscore_dict[f\"bertscore-f\"] = bertscore_data[\"bertscore\"][1].mean().item()*100\n",
    "    return bertscore_dict\n",
    "\n",
    "READ_FEATURE = {\n",
    "    \"bleu\":convert_bleu,\n",
    "    \"spbleu\":convert_spbleu,\n",
    "    \"chrf\":convert_chrf,\n",
    "    \"ter\":convert_ter,\n",
    "    \"bertscore\":convert_bertscore\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multilinear_regressor(x, y):\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(x,y)\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_regressor(x, y, regressor):\n",
    "    results = dict()\n",
    "    if type(regressor) in [Ridge, LinearRegression,Lasso,ElasticNet,GradientBoostingRegressor,DecisionTreeRegressor,RandomForestRegressor]:\n",
    "        x = list(x)\n",
    "        y_pred = regressor.predict(x).tolist()\n",
    "        y_pred_mean = np.array(y_pred).mean()\n",
    "        \n",
    "    else:\n",
    "        try:\n",
    "            x =  torch.tensor(x).t()\n",
    "            y_pred_mean = regressor(x).mean().cpu().detach().numpy()\n",
    "        except:\n",
    "            x =  torch.tensor(x)\n",
    "            y_pred_mean = regressor(x).mean().cpu().detach().numpy()\n",
    "        \n",
    "    y_mean = np.array(y).mean()\n",
    "    return (y_pred_mean, y_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data (Need Self-modification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_data(KS, dataset=\"local_flores_101/*\",model_name=\"mbart50-m2m\", split=\"train\"):\n",
    "    lang, x1, x2, y = [], [], [], []\n",
    "    x = []\n",
    "    print(f\"{dataset}/{model_name}/\")\n",
    "    all_folders = glob.glob(f\"{dataset}/{model_name}/\")\n",
    "    all_data_groups = [[f_name for f_name in glob.glob(f\"{folder}/*\") if split in f_name] \n",
    "                       for folder in all_folders]\n",
    "    for group_name in all_data_groups:\n",
    "        try:\n",
    "            if group_name and len(group_name)>=4:\n",
    "                tmp_data = dict()\n",
    "                for prefix in [\"self_src\", \"self_tgt\", \"trans_from_src\", \"trans_from_tgt\"]:\n",
    "                    suffixs = [ks[0].split(\"_\")[0] for ks in KS]\n",
    "                    for suffix in suffixs:\n",
    "                        path = '/'.join(group_name[0].split('\\\\')[:-1])\n",
    "                        with open(f\"{path}/{split}_{prefix}_corpus_{suffix}.pkl\",\"rb\") as f:\n",
    "                            data = READ_FEATURE[suffix](pickle.load(f))\n",
    "                            try:\n",
    "                                tmp_data[f\"{prefix}\"].update(data)\n",
    "                            except:\n",
    "                                tmp_data[f\"{prefix}\"] = data\n",
    "                x1.append([tmp_data[\"self_src\"][f\"{k1}-{k2}\"] \n",
    "                           for k1,k2 in KS])\n",
    "                x2.append([tmp_data[\"self_tgt\"][f\"{k1}-{k2}\"] \n",
    "                           for k1,k2 in KS])\n",
    "                x2.append([tmp_data[\"self_src\"][f\"{k1}-{k2}\"] \n",
    "                           for k1,k2 in KS])\n",
    "                x1.append([tmp_data[\"self_tgt\"][f\"{k1}-{k2}\"] \n",
    "                           for k1,k2 in KS])\n",
    "\n",
    "                y.append(tmp_data[\"trans_from_tgt\"][f\"{KS[-1][0]}-{KS[-1][1]}\"])\n",
    "                y.append(tmp_data[\"trans_from_src\"][f\"{KS[-1][0]}-{KS[-1][1]}\"])\n",
    "\n",
    "                lang.append(group_name[0].split(\"\\\\\")[1].split(\"/\")[0])\n",
    "                lang.append(\"_\".join(reversed(group_name[0].split('\\\\')[1].split(\"_\"))))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Choose the way you want to read features\n",
    "    return x1, y,lang\n",
    "#     return [xx1+xx2 for xx1,xx2 in zip(x1,x2)], y,lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flores-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant\n",
    "# REGION_1 is for the seen languages\n",
    "# REGION_2 is for the unseen languages\n",
    "REGION_1 = ['en','es','fr','de','pt','ru','it','nl','tr','pl','zh','ro','el','ja','ta','kk','km','ha','ps','gu']\n",
    "REGION_2 = ['lv','hi','jv','is','az','hy', 'cs','fi','bg','lt','et','ur','my']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features you want to read\n",
    "# KS can be in \n",
    "#        [\"chrf_max1\", \"chrf_max2\", \"chrf_max3\", \"chrf_max4\", \"chrf_max5\", \"chrf_max6\"]\n",
    "#         To\n",
    "#         [\"score\"]\n",
    "        \n",
    "#         or/and\n",
    "#         [\"bleu_max1\", \"bleu_max2\", \"bleu_max3\", \"bleu_max4\"]\n",
    "#         To\n",
    "#         [\"score\",\"counts\", \"totals\"]\n",
    "        \n",
    "#         or/and\n",
    "#         [\"spbleu_max1\", \"spbleu_max2\", \"spbleu_max3\", \"spbleu_max4\"]\n",
    "#         To\n",
    "#         [\"score\",\"counts\", \"totals\"]\n",
    "        \n",
    "#         or/and\n",
    "#         [\"bleu_final\"]\n",
    "#         To\n",
    "#         [\"score\",\"bp\",\"ref_len\",\"sys_len\"]\n",
    "        \n",
    "#         or/and\n",
    "#         [\"spbleu_final\"]\n",
    "#         To\n",
    "#         [\"score\",\"bp\",\"ref_len\",\"sys_len\"]\n",
    "        \n",
    "#         or/and\n",
    "#         [\"bertscore\"]\n",
    "#         To\n",
    "#         [\"p\",\"r\",f\"\"]\n",
    "\n",
    "KS = [(\"spbleu_final\",\"score\")]\n",
    "# model_name can be in [\"mbart50-m2m\", \"m2m-100-base\", \"m2m-100-large\", \"google_drive\"]\n",
    "model_n = \"m2m-100-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression Model\n",
    "train_x, train_y,l = read_all_data(KS,dataset=\"local_flores_101/*\", split=\"train\")\n",
    "train_x = [x for x,ll in zip(train_x,l) if all(lll in REGION_1 for lll in ll.split(\"_\"))]\n",
    "train_y = [x for x,ll in zip(train_y,l) if all(lll in REGION_1 for lll in ll.split(\"_\"))]\n",
    "model = train_multilinear_regressor(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Based On Your Need\n",
    "\n",
    "\n",
    "# Example 1: Region 1 data\n",
    "test_x, test_y,l = read_all_data(KS,dataset=\"local_flores_101/*\",split=\"test\")\n",
    "test_x = [x for x,ll in zip(test_x,l) if tuple(ll.split(\"_\")) in itertools.product(REGION_1,REGION_1)]\n",
    "test_y = [y for y,ll in zip(test_y,l) if tuple(ll.split(\"_\")) in itertools.product(REGION_1,REGION_1)]\n",
    "l = [ll for ll in l if tuple(ll.split(\"_\")) in itertools.product(REGION_1,REGION_1)]\n",
    "\n",
    "# Example 2: Region 2 data\n",
    "# test_x, test_y,l = read_all_data(KS,dataset=\"../local_flores_101/*\",model_name=model_n, split=\"test\")\n",
    "# test_x = [x for x,ll in zip(test_x,l) if tuple(ll.split(\"_\")) in itertools.product(REGION_2,REGION_2)]\n",
    "# test_y = [y for y,ll in zip(test_y,l) if tuple(ll.split(\"_\")) in itertools.product(REGION_2,REGION_2)]\n",
    "# l = [ll for ll in l if tuple(ll.split(\"_\")) in itertools.product(REGION_2,REGION_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mae = []\n",
    "pres = []\n",
    "\n",
    "model = train_multilinear_regressor(train_x, train_y)\n",
    "for tx, ty,ll in zip(test_x, test_y,l): \n",
    "\n",
    "    res = evaluate_regressor([tx], [ty], model)\n",
    "    print(ll)\n",
    "    print(max(res[0],0),res[1])\n",
    "    print()\n",
    "        \n",
    "    avg_mae.append(abs(max(res[0],0)-res[1]))\n",
    "    pres.append(max(res[0],0))\n",
    "print(mean(avg_mae))\n",
    "print(np.sqrt(np.mean((np.array(pres)-np.array(test_y))**2)))\n",
    "print(len([m for m in avg_mae if m <= 2]), len(avg_mae))\n",
    "print(stats.pearsonr(pres, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
